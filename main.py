"""
Deep Research Agent - ä¸»å…¥å£æ–‡ä»¶
è®ºæ–‡æ·±åº¦ç ”ç©¶ç³»ç»Ÿ
"""

import asyncio
import argparse
from pathlib import Path
import json
import sys

from core.base_agent import AgentConfig
from core.config import load_app_config
from core.orchestrator import OrchestratorAgent
from core.registry import get_registry


class DeepResearchSystem:
    """æ·±åº¦ç ”ç©¶ç³»ç»Ÿä¸»æ§åˆ¶å™¨"""

    def __init__(self, config_path: Path = None):
        """
        åˆå§‹åŒ–ç³»ç»Ÿ

        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
        """
        self.config = load_app_config(config_path)

        # åˆå§‹åŒ–ä¸»æ§ Agent
        self._init_agents()

    def _init_agents(self):
        """åˆå§‹åŒ–ä¸»æ§ Agent"""
        # è‡ªåŠ¨å‘ç°å¹¶æ³¨å†Œæ‰€æœ‰æ¨¡å—
        registry = get_registry()
        registry.auto_discover(['plugins', 'core'])

        llm_config = self.config.get('llm', {})

        agent_config = AgentConfig(
            name="Orchestrator",
            model=llm_config.get('model', 'claude-sonnet-4-5-20250929'),
            temperature=llm_config.get('temperature', 0.7),
            max_tokens=llm_config.get('max_tokens', 4096),
            api_key=llm_config.get('api_key'),
            provider=llm_config.get('provider'),
            base_url=llm_config.get('base_url'),
        )

        self.orchestrator = OrchestratorAgent(
            config=agent_config,
            app_config=self.config,
        )

    async def add_paper_from_arxiv(self, arxiv_id: str, full_analysis: bool = True) -> dict:
        """
        ä» arXiv æ·»åŠ è®ºæ–‡

        Args:
            arxiv_id: arXiv ID æˆ– URL
            full_analysis: æ˜¯å¦è¿›è¡Œå®Œæ•´åˆ†æ

        Returns:
            å¤„ç†ç»“æœ
        """
        print(f"\nğŸ“¥ æ­£åœ¨æ·»åŠ å¹¶åˆ†æè®ºæ–‡: {arxiv_id}")
        print("=" * 70)

        result = await self.orchestrator.add_paper(
            source='arxiv',
            identifier=arxiv_id,
            full_analysis=full_analysis
        )

        if result.get('success'):
            data = result.get('data', {})
            complete_analysis = data.get('complete_analysis', {})
            paper_info = complete_analysis.get('paper_info', {})
            knowledge = complete_analysis.get('knowledge', {})
            relations = complete_analysis.get('relations', {})

            print(f"\nâœ“ è®ºæ–‡å¤„ç†æˆåŠŸ!")
            print(f"\nğŸ“„ è®ºæ–‡ä¿¡æ¯:")
            print(f"  ID: {paper_info.get('id', 'N/A')}")
            print(f"  æ ‡é¢˜: {paper_info.get('title', 'N/A')}")
            print(f"  ä½œè€…: {', '.join(paper_info.get('authors', [])[:3])}")
            print(f"  æ¥æº: {paper_info.get('source_type', 'N/A').upper()}")

            if knowledge:
                print(f"\nğŸ’¡ çŸ¥è¯†æå–:")
                contributions = knowledge.get('contributions', [])
                print(f"  æ ¸å¿ƒè´¡çŒ®: {len(contributions)} é¡¹")
                for i, contrib in enumerate(contributions[:3], 1):
                    print(f"    {i}. {contrib.get('title', 'N/A')}")

                keywords = knowledge.get('keywords', [])
                if keywords:
                    print(f"  å…³é”®è¯: {', '.join(keywords[:8])}")

                methodology = knowledge.get('methodology', {})
                if methodology:
                    print(f"  æ–¹æ³•: {methodology.get('approach', 'N/A')[:80]}...")

            if relations:
                print(f"\nğŸ”— å…³ç³»åˆ†æ:")
                citation_analysis = relations.get('citation_analysis', {})
                print(f"  å¼•ç”¨äº†: {citation_analysis.get('num_references', 0)} ç¯‡è®ºæ–‡")
                print(f"  è¢«å¼•ç”¨: {citation_analysis.get('num_citing_this', 0)} æ¬¡")

                similarity_analysis = relations.get('similarity_analysis', {})
                num_similar = similarity_analysis.get('num_similar_papers', 0)
                print(f"  å‘ç°: {num_similar} ç¯‡ç›¸ä¼¼è®ºæ–‡")

                if num_similar > 0:
                    top_similar = similarity_analysis.get('top_similar', [])
                    print(f"  æœ€ç›¸ä¼¼è®ºæ–‡:")
                    for sim in top_similar[:3]:
                        print(f"    - {sim.get('title', 'Unknown')} (ç›¸ä¼¼åº¦: {sim.get('similarity', 0):.2f})")

                topic_analysis = relations.get('topic_analysis', {})
                if topic_analysis:
                    print(f"  ç ”ç©¶é¢†åŸŸ: {topic_analysis.get('primary_field', 'N/A')}")

                impact = relations.get('impact_analysis', {})
                if impact:
                    print(f"  å½±å“åŠ›: {impact.get('impact_level', 'Unknown')}")

        else:
            print(f"\nâœ— å¤„ç†å¤±è´¥: {result.get('error')}")

        print("=" * 70)
        return result

    async def add_paper_from_local(self, file_path: str, full_analysis: bool = True) -> dict:
        """
        ä»æœ¬åœ°æ–‡ä»¶æ·»åŠ è®ºæ–‡

        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            full_analysis: æ˜¯å¦è¿›è¡Œå®Œæ•´åˆ†æ

        Returns:
            å¤„ç†ç»“æœ
        """
        print(f"\nğŸ“„ æ­£åœ¨å¤„ç†æœ¬åœ°æ–‡ä»¶: {file_path}")
        print("=" * 70)

        result = await self.orchestrator.add_paper(
            source='local',
            identifier=file_path,
            full_analysis=full_analysis
        )

        if result.get('success'):
            print(f"\nâœ“ æ–‡ä»¶å¤„ç†æˆåŠŸ!")
            # æ˜¾ç¤ºç±»ä¼¼äº add_paper_from_arxiv çš„è¯¦ç»†ä¿¡æ¯
            data = result.get('data', {})
            complete_analysis = data.get('complete_analysis', {})
            if complete_analysis:
                paper_info = complete_analysis.get('paper_info', {})
                print(f"  æ ‡é¢˜: {paper_info.get('title', 'N/A')}")
                print(f"  æ¥æºç±»å‹: {paper_info.get('source_type', 'N/A').upper()}")

        else:
            print(f"\nâœ— å¤„ç†å¤±è´¥: {result.get('error')}")

        print("=" * 70)
        return result

    async def list_papers(self):
        """åˆ—å‡ºæ‰€æœ‰å·²æ·»åŠ çš„è®ºæ–‡"""
        # ä»å‘é‡å­˜å‚¨è·å–æ‰€æœ‰è®ºæ–‡
        all_paper_ids = self.orchestrator.vector_store.get_all_papers()

        if not all_paper_ids:
            print("\nè¿˜æ²¡æœ‰æ·»åŠ ä»»ä½•è®ºæ–‡")
            return

        print(f"\nğŸ“š å·²æ·»åŠ çš„è®ºæ–‡ ({len(all_paper_ids)} ç¯‡):")
        print("=" * 70)

        for i, paper_id in enumerate(all_paper_ids, 1):
            paper = self.orchestrator.vector_store.get_paper_by_id(paper_id)
            if paper:
                metadata = paper.get('metadata', {})
                print(f"\n{i}. {metadata.get('title', 'N/A')}")
                print(f"   ID: {paper_id}")
                print(f"   ä½œè€…: {metadata.get('authors', 'N/A')}")
                print(f"   ç±»å‹: {metadata.get('source_type', 'N/A').upper()}")
                if metadata.get('year'):
                    print(f"   å¹´ä»½: {metadata.get('year')}")

        print("=" * 70)

    async def show_statistics(self):
        """æ˜¾ç¤ºç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯"""
        stats = self.orchestrator.get_statistics()

        print(f"\nğŸ“Š ç³»ç»Ÿç»Ÿè®¡:")
        print("=" * 70)

        vector_stats = stats.get('vector_store', {})
        print(f"\nå‘é‡æ•°æ®åº“:")
        print(f"  è®ºæ–‡æ•°é‡: {vector_stats.get('num_papers', 0)}")

        graph_stats = stats.get('knowledge_graph', {})
        print(f"\nçŸ¥è¯†å›¾è°±:")
        print(f"  èŠ‚ç‚¹æ•°: {graph_stats.get('num_papers', 0)}")
        print(f"  è¾¹æ•°: {graph_stats.get('num_edges', 0)}")
        print(f"  å¼•ç”¨å…³ç³»: {graph_stats.get('num_citations', 0)}")
        print(f"  ç›¸ä¼¼åº¦è¾¹: {graph_stats.get('num_similarity_edges', 0)}")

        influential = stats.get('influential_papers', [])
        if influential:
            print(f"\næœ€æœ‰å½±å“åŠ›çš„è®ºæ–‡ (Top 5):")
            for i, paper in enumerate(influential, 1):
                print(f"  {i}. {paper.get('title', 'Unknown')} ({paper.get('citations', 0)} æ¬¡å¼•ç”¨)")

        print("=" * 70)

    async def search_papers(self, query: str, top_k: int = 5):
        """æœç´¢è®ºæ–‡"""
        print(f"\nğŸ” æœç´¢: '{query}'")
        print("=" * 70)

        results = self.orchestrator.search_papers(query, top_k=top_k)

        if not results:
            print("\næ²¡æœ‰æ‰¾åˆ°ç›¸å…³è®ºæ–‡")
            return

        print(f"\næ‰¾åˆ° {len(results)} ç¯‡ç›¸å…³è®ºæ–‡:\n")

        for i, result in enumerate(results, 1):
            metadata = result.get('metadata', {})
            similarity = result.get('similarity', 0)
            print(f"{i}. {metadata.get('title', 'Unknown')} (ç›¸ä¼¼åº¦: {similarity:.3f})")
            print(f"   ID: {result.get('paper_id', 'N/A')}")
            print(f"   ä½œè€…: {metadata.get('authors', 'N/A')}")
            print()

        print("=" * 70)

    def start_web_interface(self):
        """å¯åŠ¨ Web ç•Œé¢"""
        print("\nğŸŒ å¯åŠ¨ Web ç•Œé¢...")
        print("=" * 60)
        print("åŠŸèƒ½å¼€å‘ä¸­...")
        print("=" * 60)
        # TODO: å®ç° Web ç•Œé¢


async def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="Deep Research Agent - è®ºæ–‡æ·±åº¦ç ”ç©¶ç³»ç»Ÿ"
    )

    parser.add_argument(
        '--config',
        type=str,
        default='config/config.yaml',
        help='é…ç½®æ–‡ä»¶è·¯å¾„'
    )

    parser.add_argument(
        '--arxiv',
        type=str,
        help='æ·»åŠ  arXiv è®ºæ–‡ (ID æˆ– URL)'
    )

    parser.add_argument(
        '--local',
        type=str,
        help='æ·»åŠ æœ¬åœ°è®ºæ–‡æ–‡ä»¶'
    )

    parser.add_argument(
        '--list',
        action='store_true',
        help='åˆ—å‡ºæ‰€æœ‰å·²æ·»åŠ çš„è®ºæ–‡'
    )

    parser.add_argument(
        '--stats',
        action='store_true',
        help='æ˜¾ç¤ºç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯'
    )

    parser.add_argument(
        '--search',
        type=str,
        help='æœç´¢è®ºæ–‡'
    )

    parser.add_argument(
        '--quick',
        action='store_true',
        help='å¿«é€Ÿæ¨¡å¼ï¼ˆä»…æ‘„å…¥ï¼Œä¸è¿›è¡Œæ·±åº¦åˆ†æï¼‰'
    )

    parser.add_argument(
        '--web',
        action='store_true',
        help='å¯åŠ¨ Web ç•Œé¢'
    )

    args = parser.parse_args()

    # æ£€æŸ¥é…ç½®æ–‡ä»¶
    config_path = Path(args.config)
    if not config_path.exists() and config_path.name != 'config.yaml':
        print(f"âš ï¸  é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
        print(f"å°†ä½¿ç”¨é»˜è®¤é…ç½®")
        config_path = None

    # åˆå§‹åŒ–ç³»ç»Ÿ
    system = DeepResearchSystem(config_path)

    # æ‰§è¡Œå‘½ä»¤
    if args.arxiv:
        full_analysis = not args.quick
        await system.add_paper_from_arxiv(args.arxiv, full_analysis=full_analysis)

    elif args.local:
        full_analysis = not args.quick
        await system.add_paper_from_local(args.local, full_analysis=full_analysis)

    elif args.list:
        await system.list_papers()

    elif args.stats:
        await system.show_statistics()

    elif args.search:
        await system.search_papers(args.search)

    elif args.web:
        system.start_web_interface()

    else:
        # äº¤äº’æ¨¡å¼
        print("\nğŸš€ Deep Research Agent - è®ºæ–‡æ·±åº¦ç ”ç©¶ç³»ç»Ÿ")
        print("=" * 70)
        print("æ¬¢è¿ä½¿ç”¨åŸºäºå¤š Agent åä½œçš„æ™ºèƒ½è®ºæ–‡ç®¡ç†ç³»ç»Ÿ!")
        print("\nâœ¨ æ ¸å¿ƒç‰¹æ€§:")
        print("  â€¢ TeX æºæ–‡ä»¶ä¼˜å…ˆè§£æï¼ˆæ›´å‡†ç¡®çš„ç»“æ„åŒ–ä¿¡æ¯ï¼‰")
        print("  â€¢ AI é©±åŠ¨çš„çŸ¥è¯†æå–å’Œå…³ç³»åˆ†æ")
        print("  â€¢ è‡ªåŠ¨æ„å»ºçŸ¥è¯†å›¾è°±å’Œå¼•ç”¨ç½‘ç»œ")
        print("  â€¢ è¯­ä¹‰æœç´¢å’Œç›¸ä¼¼è®ºæ–‡å‘ç°")
        print("\nğŸ“– å¯ç”¨å‘½ä»¤:")
        print("  python main.py --arxiv <ID>        # æ·»åŠ  arXiv è®ºæ–‡ï¼ˆå®Œæ•´åˆ†æï¼‰")
        print("  python main.py --arxiv <ID> --quick # å¿«é€Ÿæ·»åŠ ï¼ˆä»…æ‘„å…¥ï¼‰")
        print("  python main.py --local <file>      # æ·»åŠ æœ¬åœ°è®ºæ–‡")
        print("  python main.py --list              # åˆ—å‡ºæ‰€æœ‰è®ºæ–‡")
        print("  python main.py --stats             # æŸ¥çœ‹ç³»ç»Ÿç»Ÿè®¡")
        print("  python main.py --search <query>    # æœç´¢è®ºæ–‡")
        print("  python main.py --web               # å¯åŠ¨ Web ç•Œé¢")
        print("\nğŸ’¡ ç¤ºä¾‹:")
        print("  python main.py --arxiv 2301.00001")
        print("  python main.py --arxiv https://arxiv.org/abs/2401.12345")
        print("  python main.py --search 'transformer attention mechanism'")
        print("  python main.py --stats")
        print("=" * 70)


if __name__ == "__main__":
    asyncio.run(main())
