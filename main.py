"""
Deep Research Agent - é€šç”¨ä»»åŠ¡å…¥å£

é›¶é¢†åŸŸçŸ¥è¯†ï¼šæ‰€æœ‰é¢†åŸŸé€»è¾‘ç”± plugins æä¾›ï¼Œcore åªåšé€šç”¨è°ƒåº¦ã€‚
"""

import asyncio
import argparse
from pathlib import Path

from core.config import load_app_config
from core.registry import get_registry


class TaskSystem:
    """é€šç”¨ä»»åŠ¡ç³»ç»Ÿ"""

    def __init__(self, config_path=None):
        self.config = load_app_config(config_path)
        self._registry = get_registry()
        self._registry.auto_discover(['plugins', 'core'])

    async def chat_execute(self, message: str, history: list = None) -> str:
        """é€šè¿‡ LLM + tool-use æ‰§è¡Œä»»åŠ¡ï¼ˆä½¿ç”¨ ToolUseRunnerï¼‰"""
        from core.chat_router import _get_llm_client, _get_system_prompt, execute_tool, get_all_tools
        from core.tool_use_runner import ToolUseRunner

        client, model = _get_llm_client()
        messages = [{"role": m["role"], "content": m["content"]} for m in (history or [])]
        messages.append({"role": "user", "content": message})

        runner = ToolUseRunner(
            client=client,
            model=model,
            system_prompt=_get_system_prompt(),
            tools=get_all_tools(),
            execute_tool=execute_tool,
            on_text=lambda text: print(text),
            on_tool_call=lambda name, _: print(f"  â†’ {name}"),
        )
        return await runner.run(messages)

    async def interactive(self):
        """äº¤äº’å¼ chat å¾ªç¯"""
        print("\nğŸš€ Deep Research Agent")
        print("=" * 50)
        print("è¾“å…¥ä»»åŠ¡æè¿°ï¼ŒAI è‡ªåŠ¨ç¼–æ’æ‰§è¡Œã€‚è¾“å…¥ quit é€€å‡ºã€‚")
        print("=" * 50)

        history = []
        while True:
            try:
                user_input = input("\n> ")
            except (EOFError, KeyboardInterrupt):
                print("\nå†è§ï¼")
                break

            if user_input.strip().lower() in ('quit', 'exit', 'q'):
                print("å†è§ï¼")
                break

            if not user_input.strip():
                continue

            response = await self.chat_execute(user_input, history)
            history.append({"role": "user", "content": user_input})
            history.append({"role": "assistant", "content": response})

    def start_server(self):
        """å¯åŠ¨ FastAPI æœåŠ¡"""
        import uvicorn
        uvicorn.run("backend.main:app", host="0.0.0.0", port=8000, reload=True)


async def main():
    parser = argparse.ArgumentParser(
        description="Deep Research Agent - é€šç”¨ä»»åŠ¡ç³»ç»Ÿ"
    )
    parser.add_argument(
        'task', nargs='?', default=None,
        help='ä»»åŠ¡æè¿°ï¼ˆè‡ªç„¶è¯­è¨€ï¼‰ï¼Œç”± LLM ç¼–æ’æ‰§è¡Œ'
    )
    parser.add_argument(
        '--config', type=str, default='config/config.yaml',
        help='é…ç½®æ–‡ä»¶è·¯å¾„'
    )
    parser.add_argument(
        '--server', action='store_true',
        help='å¯åŠ¨ FastAPI æœåŠ¡ (port 8000)'
    )

    args = parser.parse_args()

    config_path = Path(args.config)
    if not config_path.exists() and config_path.name != 'config.yaml':
        print(f"âš ï¸  é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}ï¼Œå°†ä½¿ç”¨é»˜è®¤é…ç½®")
        config_path = None

    system = TaskSystem(config_path)

    if args.server:
        system.start_server()
    elif args.task:
        await system.chat_execute(args.task)
    else:
        await system.interactive()


if __name__ == "__main__":
    asyncio.run(main())
